\documentclass{article}
\usepackage{comment}
\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage{fancyhdr}
\usepackage[round]{natbib}
\usepackage{graphicx}
\usepackage{url}
\usepackage{amsmath}
\usepackage{amssymb}
\DeclareMathOperator*{\argmax}{argmax}
\DeclareMathOperator*{\argmin}{argmin}
\pagenumbering{arabic}
\usepackage{multicol}
\usepackage{siunitx}
\usepackage{soul}

\pagestyle{fancy}
\fancyhf{}
\rhead{Mohammad Rahmani}
\lhead{Self-awareness}

\newcommand{\ignore}[1]{}
\begin{document}
	\bibliographystyle{plainnat}
	\title{Self-awareness survey}
	\author{Mohammad Rahmani}
	\date{}
	\maketitle
	Upcoming IEEE proceedings
	\url{https://proceedingsoftheieee.ieee.org/view-recent-issues/july-2020/}
	There are four types of AI
	\begin{itemize}
		\item  REACTIVE MACHINES
	    \item  LIMITED MEMORY
	    \item  THEORY OF MIND
		\item  SELF-AWARENESS
	\end{itemize}
	\section{Topics}
		\subsection{Knowledge representation and modeling structures and Trade-offs}
		\cite{minku-2016-knowledge-representation-and-modelling-structures-and-trade-offs}
		
	\section{Related terms and notices}
		\begin{itemize}
			\item self-modeling robot \citep{kwiatkowski-2019-task-agnostic-self-modeling-machines}
			\item Artificial consciousness: Self-awareness is a subtopic of artificial consciousness \url{https://en.wikipedia.org/wiki/Artificial_consciousness}. Consciousness alone means: Consciousness at its simplest is "awareness or sentience of internal or external existence" \url{https://en.wikipedia.org/wiki/Consciousness}.
			\item Self-expression \citep{lewis-2011-a-survey-of-self-awareness-and-its-application-in-computing-systems}
			\item Natural science computing
			\item evolutionary robotics
		\end{itemize}
	
	\section{Assessment}
		\citet{herbst-2017-metrics-and-benchmarks-for-self-aware-computing-systems}
		\citet{esterle-2017-assessing-self-awareness}
	\section{Definitions}
		\paragraph{Self-awareness}
		\textbf{Literal definitions}
		 \begin{itemize}
		 	\item implies that Self-awareness must first rely on perception of self as different from the environment and from other agents \cite{chatila-2018-toward-self-aware-robots}.
		 	\item Self-awareness models make it possible for an agent to evaluate whether faced situations at a given time correspond to previous experiences \cite{ravanbakhsh-2018-hierarchy-of-gans-for-learning-embodied-self-awareness-model}.
		 \end{itemize}
		
		\paragraph{General definition} The capacity to become the object of one’s \textbf{own attention}, which arises when an agent focuses \textbf{not only} on the \textbf{external environment} but also on the \textbf{internal milieu}. The agent becomes a \textbf{reflective observer}, \textbf{processing self-information.} It becomes \textbf{aware} that it is \textbf{awake} and actually experiencing \textbf{specific mental events}, \textbf{emitting behaviors}, and \textbf{possessing unique characteristics} \citet{morin-2006-levels-of-consciousness-and-self-awareness-a-comparison-and-integration-of-various-neurocognitive-views}.
		\paragraph{Ego-thing} go-Things are defined as intelligent
		systems that perceive their internal parameters and adapt them-
		selves when facing non-stationary situations. \citet{kanapram-2019-dynamic-bayesian-approach-for-decision-making-in-ego-things}[5]
		\paragraph{Private/Public(shared) self-awareness - Subjective/Objective}  \citet{regazzoni-2020-multi-sensorial-generative-and-descriptive-self-awareness-models-for-autonomous-systems}[2]
			\begin{itemize}
				\item \textbf{Private} Private self-aspects relate to externally \textbf{unobservable} events and characteristics such as emotions, physiological sensations, perceptions, values, goals, and motives
				\item \textbf{Public} self-aspects are visible attributes such as behavior and physical appearance
			\end{itemize}
			Also check more detailed in \cite{lewis-2011-a-survey-of-self-awareness-and-its-application-in-computing-systems} II-A and \cite{baydoun-2018-a-multi-perspective-approach-to-anomaly-detection-for-self-aware-embodied-agents} Introduction.
		\section{Levels of self-awareness}
			As stated in
			\cite{lewis-2011-a-survey-of-self-awareness-and-its-application-in-computing-systems} II-B
			As \citet{neisser-1997-the-roots-of-self-knowledge-perceiving-self-it-and-thou} these leves of self awareness could be introduced: (See a more modern list in \cite{lewis-2017-towards-a-framework-for-the-levels-and-aspects-of-self-aware-computing-systems})
			\begin{itemize}
				\item \textbf{Ecological self} The ecological self is the most minimal form of self-awareness. It provides only for basic stimulus	response interaction, as the organism has a basic awareness of stimuli. The ecological self can be thought of as the minimum requirement for the organism to not be unconscious.
				
				\item \textbf{Interpersonal self} The interpersonal self enables the organism to possess a simple awareness of its external interactions, permitting limited adaptation to others in the performance of tasks.
				
				\item \textbf{Extended self} The extended self extends the interpersonal self to permit reflection of interactions over time. The organism is aware of the existence of past and future
				
				\item \textbf{Private self} The private self includes that the individual can process more advanced information concerning itself,
				
				\item \textbf{Conceptual self}: The conceptual self (or self-concept) is the most advanced form of self-awareness, representing that
				the organism is capable of constructing and reasoning about an abstract symbolic representation of itself
			\end{itemize}
			There is a newer list in \cite{lewis-2017-towards-a-framework-for-the-levels-and-aspects-of-self-aware-computing-systems}
		\section{Reflective and Meta-reflective Self-awareness}
			All taken from \cite{lewis-2017-towards-a-framework-for-the-levels-and-aspects-of-self-aware-computing-systems}
			\subsection{Aspects of Reflective and Meta-reflective Self-awareness}
				\subsubsection{Identity Awareness}
				\subsubsection{State Awareness}
				\subsubsection{Time Awareness}
				\subsubsection{Interaction Awareness}In interaction awareness, run-time models are used to take into account patterns of interactions between entities. There are various sub-aspects here, which build on each other. Most obviously, the system must be able to recognize that some actions form part of interactions, such that they are in some way causally connected. An example of this includes message passing, such as is used in a communications protocol, where one message may be a response to another, rather than an isolated action.
				There may be, in simple interaction awareness, simply a model of the flow of actions over time (e.g., action b typically occurs after action a), or there may be additional semantics associated with the actions or the combination of them (e.g., actions b is a response and action a is a query).
					\paragraph{} As a prerequisite to the above form of interaction awareness, there must be some form of identity awareness, at least insofar that the system can identify messages, as apart from the general noise in the environment. It may also be important to be able to identify individuals as those engaged in an interaction, if not in terms of their
					unique identity, then perhaps in terms of role.
					\paragraph{} Interaction awareness can also build upon state awareness, since models may encapsulate knowledge of causality such as “when action a is taken in state s, this leads to state t.” Markovian approaches may be effective choices for modeling state based interaction awareness.
					\paragraph{} Finally, the interactions need not be external. Causality of internal processes may also be modeled in meta-reflective processes. For example, a system might model the behavior of one of its own decision-making processes, when other parts of the system are either operational or not. In the former case, the system may learn a model of how decision-making degrades (due to more stringent resource constraints), when load elsewhere is high. Such models of internal causality may then be used to provide adaptive internal re-architecting, or perhaps more effective scheduling of tasks.
					
				\subsubsection{Behavior Awareness}
				\subsubsection{Appearance Awareness}
				\subsubsection{Goal Awareness}
				\subsubsection{Belief Awareness}
				\subsubsection{Expectation Awareness}
		\section{Domain of self-awareness} \cite{lewis-2017-towards-a-framework-for-the-levels-and-aspects-of-self-aware-computing-systems}
		
		\section{Meta-Cognition}
			The higher levels of self-awareness, such as meta-self-awareness introduced in section \citet{lewis-2011-a-survey-of-self-awareness-and-its-application-in-computing-systems}II-B, can also be viewed as
			meta-cognition, defined \citet{overschelde-2008-metacognition-knowing-about-knowing} as knowing about knowing.
		
		\section{Uncat}
			\paragraph{Approaches to tackle SA} Common aspects of the proposed approaches lie on the conception of SA as 
			\begin{itemize}
				\item A cognitive embodied process composed of representational and inferential operations of an agent situated in an environment,
				\item An agent’s property which emerges in various forms, including the extent of the SA capabilities (“levels”) \citet{regazzoni-2020-multi-sensorial-generative-and-descriptive-self-awareness-models-for-autonomous-systems}[1], \citet{regazzoni-2020-multi-sensorial-generative-and-descriptive-self-awareness-models-for-autonomous-systems}[6] and the scope of the processed information (“private and public”) \citet{regazzoni-2020-multi-sensorial-generative-and-descriptive-self-awareness-models-for-autonomous-systems}[2], \citet{regazzoni-2020-multi-sensorial-generative-and-descriptive-self-awareness-models-for-autonomous-systems}[7]
			\end{itemize}
		
		\section{Application of SA} More recently, SA concepts have been transferred to artificial systems aiming at either 
			\begin{itemize}
				\item Designing intelligent agents
				\item Analyzing their behavior
			\end{itemize}
			\paragraph{Why SA in AI?} The driving motivation for the transfer of biological SA concepts
			to artificial systems is to improve:
			\begin{itemize}
				\item autonomy
				\item robustness
				\item scalability
			\end{itemize}
			and have been investigated in different fields, including software engineering, machine learning, and robotics \citet{regazzoni-2020-multi-sensorial-generative-and-descriptive-self-awareness-models-for-autonomous-systems}[8],
			\citet{regazzoni-2020-multi-sensorial-generative-and-descriptive-self-awareness-models-for-autonomous-systems}[9], \citet{regazzoni-2020-multi-sensorial-generative-and-descriptive-self-awareness-models-for-autonomous-systems}[10], \citet{regazzoni-2020-multi-sensorial-generative-and-descriptive-self-awareness-models-for-autonomous-systems}[11], \citet{regazzoni-2020-multi-sensorial-generative-and-descriptive-self-awareness-models-for-autonomous-systems}[12], \citet{regazzoni-2020-multi-sensorial-generative-and-descriptive-self-awareness-models-for-autonomous-systems}[13], \citet{regazzoni-2020-multi-sensorial-generative-and-descriptive-self-awareness-models-for-autonomous-systems}[14], \citet{regazzoni-2020-multi-sensorial-generative-and-descriptive-self-awareness-models-for-autonomous-systems}[15]. 
			\paragraph{Challenge}: A fundamental challenge in most of these approaches is how to systematically integrate SA capabilities into artificial agents.
		
	\section{Prospective/exteroceptive sensory data}: 
		\cite{regazzoni-2020-multi-sensorial-generative-and-descriptive-self-awareness-models-for-autonomous-systems} Fig 1).
		\subsection{Proprioceptive sensors} 
		They measure the internal agent's parameters
		
		\subsection{Extroceptive sensors}
		exteroceptive sensors observe the agent's environment.
			\paragraph{Extended environment}
				Extended environment is beyond direct perception of an agent.
	\begin{figure*}
		\centering
		\includegraphics[width=0.7\textwidth]{/home/donkarlo/Dropbox/projs/research/assets/regazzoni-2020-multi-sensorial-generative-and-descriptive-self-awareness-models-for-autonomous-systems-fig-1.png}
		\caption{\citet{regazzoni-2020-multi-sensorial-generative-and-descriptive-self-awareness-models-for-autonomous-systems}}
		\label{fig:regazzoni-2020-multi-sensorial-generative-and-descriptive-self-awareness-models-for-autonomous-systems-fig-1.jpg}
	\end{figure*}
		
	\paragraph{SA introspection}  The SA representation obtained by jointly and dynamically analyzing the sensory data endows the agent with introspection at different hierarchical levels. Introspection associates with the agent’s capability of estimating and representing \emph{dynamical causal relationships} from the observed sensory data. Such representation allows the agent to model interactions between itself, as observed through proprioceptive sensors; and the environment, as observed through exteroceptive sensors.
		
	\paragraph{importance of embodying SA capabilities}The extent of the embodied SA capabilities influences the agent's performance when solving tasks and are assumed as reasons for the significant capability differences of the various biological species. 
		
		\section{Requirements to consider an agent self-aware}The following capabilities as the minimum requirements in to consider an agent self-aware:
			\citet{regazzoni-2020-multi-sensorial-generative-and-descriptive-self-awareness-models-for-autonomous-systems} Table I describes the proposed SA capabilities and provides a relationship between each of them and biological agents, demonstrating how humans address these capabilities.
			\subsection{Initialization}
				\subsection{Reference task} \cite{regazzoni-2020-multi-sensorial-generative-and-descriptive-self-awareness-models-for-autonomous-systems,kanapram-2019-dynamic-bayesian-approach-for-decision-making-in-ego-things,kanapram-2019-self-awareness-in-intelligent-vehicles-experience-based-abnormality-detection,kanapram-2020-collective-awareness-for-abnormality-detection-in-connected-autonomous-vehicles,baydoun-2018-learning-switching-models-for-abnormality-detection-for-autonomous-driving} have used this method. That is, they had a vehicle and they had a rectangular path along which an automatic vehicle was driven by a human driver. This builds the normal task. 
				\subsubsection{Random Walk} \cite{regazzoni-2020-multi-sensorial-generative-and-descriptive-self-awareness-models-for-autonomous-systems} claimed it was used in \citep{kanapram-2019-dynamic-bayesian-approach-for-decision-making-in-ego-things}
				\subsubsection{Human/IA helped initialization} Such as human-agent driving of an Autonomous Car in an (AV)
				\subsubsection{Self Modeling}
				\citet{bellman-2017-self-modeling-and-self-awareness}
				\citet{kwiatkowski-2019-zero-shot-learning-on-simulated-robots}	
				\citet{kwiatkowski-2019-task-agnostic-self-modeling-machines}
				By inner speech \cite{chella-2020-developing-self-awareness-in-robots-via-inner-speech}
			\subsection{Memorization}
			\subsection{Inference/prediction}
				\paragraph{DBN} 
				Dynamic systems are systems whose states evolve over the course of time. In other words their future state can be described by first order differential equation of their current state on time. MJLS - MJPF \citep{baydoun-2018-learning-switching-models-for-abnormality-detection-for-autonomous-driving}
			\subsection{Anomaly detection}
				Abnormality is defined by the difference between prediction and observation. So for anomaly detection these two factors usually are needed:
				\begin{itemize}
					\item Predicting model
						Filtering is the matter of estimating an unknown Probability Mass Function (PMF). A popular use case of filtering methods is in robotics where a robot tries to estimate its location after a set of actions it has performed.
						\begin{itemize}
							\item \textbf{Kalman Filtering (KF)} \cite{simon-2010-kalman-filtering-with-state-constraints-a-survey-of-linear-and-nonlinear-algorithms}
							An example for Bayesian filter using a dynamic model is the Kalman Filter (KF), an optimal state estimator for linear
							dynamic systems with Gaussian noise iteratively predicting and estimating states from incremental observations. The
							posterior probability density function (PDF) of the continuous state in the KF is Gaussian.
							\item \textbf{Particle Filtering (PF)} \cite{gustafsson-2010-particle-filter-theory-and-practice-with-positioning-applications}
							A Particle Filter (PF) allows one
							to manage a numerical approximation of the posterior in a
							nonlinear, non-Gaussian Bayesian filtering problem. PF
							approximates PDFs with a set of weighted samples (particles),
							which are propagated with an iterative random process. Particles are re-weighted based on dynamics and a likelihood score
							that depends on new observations.
							\item \textbf{Markov Jump Linear System (MJLS)} \cite{doucet-2001-particle-filters-for-state-estimation-of-jump-markov-linear-systems}
							\item \textbf{Markov Jump Particle Filter (MJPF)} is formed of KP+PF and follows the same direction as MJLS
								\cite{baydoun-2018-learning-switching-models-for-abnormality-detection-for-autonomous-driving}
								a method to jointly learn coupled
								KF and PF models from a training sequence of state-dependent
								actions. Such filters are jointly used to perform Bayesian
								inference on a learned plan model. They are used to predict
								and estimate the states of a moving agent.
						\end{itemize}
					\item A metric to measure 
						\begin{itemize}
							\item \textbf{Hellinger distance} Introduced in \cite{lourenzutti-2014-the-hellinger-distance-in-multicriteria-decision-making-an-illustration-to-the-topsis-and-todim-methods} and used in \cite{regazzoni-2020-multi-sensorial-generative-and-descriptive-self-awareness-models-for-autonomous-systems,kanapram-2019-self-awareness-in-intelligent-vehicles-experience-based-abnormality-detection,kanapram-2020-collective-awareness-for-abnormality-detection-in-connected-autonomous-vehicles}
							\item \textbf{Bhattacharya distance} used in \cite{baydoun-2018-learning-switching-models-for-abnormality-detection-for-autonomous-driving}
						\end{itemize}
				\end{itemize}
				\paragraph{\cite{baydoun-2018-learning-switching-models-for-abnormality-detection-for-autonomous-driving}}
					\begin{itemize}
						\item The example is is their customary example. The iCab 
						\item The continuous space of status is formed of X= [x,y,x',y'] where [x,y] is the position in the rectangular courtyard of Genoa university and (x'=dx/dt,y'=dy/dt)  is the velocity vector.
						\item It uses Self organising maps (SOM) to to make the above space discrete (shown by S/the vocabulary) (In their forthcoming papers they used Growing Neural Gas)
						\item For the first time it introduced Markov Jump Particle Filter (MJPF) in this paper and they used it in their recent papers including yours. That's why it clarify gradually everything back. MJPF predicts (filters) states in two levels. Kolman F. is responsible for predicting from previous X to next X and Particle filter is responsible for Predicting from previous S to nex S (previous=time stamp k-1, nex= time stamp k) 
						\item Now that there is method to predict, it introduces three metrics for abnormality prediction db1 (eq 18), db2 (eq 19, just assumes that Z happens close to X), y (eq 21 based on weighted distance described in Eq5)
						\item They tested like this: a human rode the vehicle along the rectangular courtyard.  Please notice that they say that location data had 10 cm position accuracy (this is what forms the difference between Z(observation/what is measured by sensors) and X(true status))
						\item In the next phase they performed three different maneuvers when the normal rectangular path (reference task in your paper) is interrupted. 1. turning around the pedestrian (called avoidance abnormality Fig 7) 2. U-turn (returning back Fig 4c , abnormality Fig 8) 3. And stopping until the pedestrian goes away from the cam view. (abnormality Fig 9)
						\item Why this paper is important? Abnormality indexes use the generated discrete states in their calculation but the results in Fig 7,8,9 show how well extracted abnormalities from reference task matches the times in the three cases that the pedestrian interrupted the path in all three maneuvers.  So their abnormality indexes are maneuver independent, can work on discreet data etc. This discreet state space can form a vocabulary.
					\end{itemize}
				\paragraph{\cite{kanapram-2019-dynamic-bayesian-approach-for-decision-making-in-ego-things}}
				This paper has used MJPF (Markov Jump Particle Filter) and Hellinger distance for feature selection. It wants to pick a feature which is more accurate in predicting and abnormality detection. 
				Normal task is turning around the rectangular of university courtyard without any obstacle and abnormal is the time that the AV has to perform a U-turn when an obstacle interrupts the perimeter. While performing the normal task it gathers 3 sensory data Steering,Velocity and power. Then it uses GNG to make space state and generate the alphabet of state space and then it puts together the centroid of each cluster and it's time derivatives in one set as a word. (Although position is not measured here but you can consider the state space like [x,y,vx,vy] and then have one GNG for positions and another for speeds. then each word is made of the centroid of a position class and the centroid of a speed class). Now that we have words, we can use MJPF to observe continuous data and predict the next time-step discrete data (the next word). By this prediction and hellinger distance (eq 5) we can measure the abnormality arises from taught DBN for normal task against the U-turn. On page 5 it tested eq 5 (using the learned MJPF from the normal task) for several features and table 1 on page 7 shows the best feature which eq 5 can get its abnormality and provide better prediction is SP (S=steering, P=Power). (I personally expected SV is the best feature, but MJPF proves that it is better to consider power instead of velocity).  
				
				\paragraph{\cite{baydoun-2018-a-multi-perspective-approach-to-anomaly-detection-for-self-aware-embodied-agents}} In this paper, anomaly detection was tackled from two layers of self-awareness. The Shared-level (SL) and Private Level (PL). SL is what is visible by an external observer but PL is only available to the agent. SL is considered the position and velocity of an Autonomous Vehicle (AV) which is observable by an external observer and PL is the video frames captured by the AV. Anomaly detection is performed by training two different models on a reference experience (in this paper, it is called Environment Center (EC) Model, in SA models such as \cite{regazzoni-2020-multi-sensorial-generative-and-descriptive-self-awareness-models-for-autonomous-systems} these reference tasks form initial models) and comparing their predication with the observations from a new task/experience. The reference task is perimeter monitoring (PM) of the rectangular courtyard of Genoa university and the new experience is when this rectangular path is interrupted by a pedestrian twice (Fig 3, a and b). For SL abnormality detection, they have used Gaussian Process (GP) to divide the perimeter into quasi-constant velocity zones (speed is constant in these zones) and over these zones they have trained a bank of Kalman Filters (KFs) for regional position estimation. A sample of such perimeter partitioning can be seen in Fig 7. During the new experience, the distance between KFs bank prediction (trained during the reference task) and the observations come from online, new experience, forms the abnormality measurements which is presented in Equation (3) and graphed in Figure (5).  It has captured four times the presence of a pedestrian in two times circling around the perimeter and even 8 times (but lower than the abnormality threshold) the corners of the perimeter. To tackle PL abnormality detection, they have used a GAN with two discriminator and two generators. Each G-D pair is responsible to predict-score once from frame to optical flow and once from optical-flow to frame. GP zones (from the previous experience), will be used here to train a bank of discriminators (similar to banks of KFs) for scoring predicted data from generators. This whole process is performed for two sets in two GANs (GAN 1 and GAN 2). Set1 is for learning straight paths and Set2 for training curves. The abnormality resulted from Eq(4) is used to create Fig 6. The new abnormality which is the result of minimum of GAN 1 and GAN 2, resulted in a better description of the new experience because not only it can detect the presence of a pedestrian 4 times in two laps, but also it can predict abnormality (pedestrian presence) a few moments before and capture camera's noise on straight paths because of AV's higher speed.                                                
				
			\subsection{Model creation}
				\subsection{Incremental learning}
				Wikipedia Ref\footnote{\url{https://en.wikipedia.org/wiki/Incremental_learning#:~:text=In\%20computer\%20science\%2C\%20incremental\%20learning,to\%20further\%20train\%20the\%20model.}}
				\subsection{}
			\subsection{Inference with control (Decision making)}
		
		\begin{figure*}
			\centering
			\includegraphics[width=0.7\textwidth]{/home/donkarlo/Dropbox/projs/research/assets/regazzoni-2020-multi-sensorial-generative-and-descriptive-self-awareness-models-for-autonomous-systems-table-i.png}
			\caption{Table I}
			\label{fig:regazzoni-2020-multi-sensorial-generative-and-descriptive-self-awareness-models-for-autonomous-systems-table-i.jpg}
		\end{figure*}
	\section{Computing architectures}
		\cite{sanz-2009-systems-models-and-self-awareness-towards-architectural-models-of-consciousness}
	\section{bio-inspired self-awareness theories}
		\subsection{Damasio’s Model} \url{https://en.wikipedia.org/wiki/Damasio\%27s_theory_of_consciousness} and \citet{damasio-1999-the-feeling-of-what-happens-body-and-emotion-in-the-making-of-consciousness}
			\paragraph{autobiographical memories (AMs)} Neuroscientists such as Damasio \citet{regazzoni-2020-multi-sensorial-generative-and-descriptive-self-awareness-models-for-autonomous-systems}[28] have provided evidence that neural patterns in the oldest parts of the human brain are organized to process and combine proprioceptive and exteroceptive sensorial information according to hierarchical neural layouts culminating into so-called \emph{autobiographical memories (AMs)}. 
			\\
			AMs can constitute a sort of database for memorizing models of \textbf{episodes} that the agent has learned from previous experiences \citet{regazzoni-2020-multi-sensorial-generative-and-descriptive-self-awareness-models-for-autonomous-systems}[5]. 
			\\
			Bio-inspired AMs have already been investigated towards implementing self-awareness in
			artificial agents, for example, in \citet{regazzoni-2020-multi-sensorial-generative-and-descriptive-self-awareness-models-for-autonomous-systems}[29]. Based on anatomical observations, Damasio suggests that episodes in AMs are \textbf{represented by a language coding proprioceptive and exteroceptive information according to a temporally ordered causal representation.} Fig. 2 depicts the combination of estimations
			of the agent’s own the external world’s state obtained by an
			early neural layout (named “proto” and “core”, respectively)
			in the form of temporal-causal AM patterns.
			\begin{figure*}
				\centering
				\includegraphics[width=0.7\textwidth]{/home/donkarlo/Dropbox/projs/research/assets/regazzoni-2020-multi-sensorial-generative-and-descriptive-self-awareness-models-for-autonomous-systems-fig-2.png}
				\caption{regazzoni-2020-multi-sensorial-generative-and-descriptive-self-awareness-models-for-autonomous-systems-fig-2.png}
				\label{fig:regazzoni-2020-multi-sensorial-generative-and-descriptive-self-awareness-models-for-autonomous-systems-fig-2.png}
			\end{figure*}
			\paragraph{} According to Damasio, AM patterns are based on \emph{first-person situational descriptors} that enable human agents to represent experienced episodes on the basis of a \textbf{neural vocabulary} (i.e., information units). These descriptors always represent exteroceptive data as contextualized to information coming from the agent's body, and vice versa. Thus, patters encoding episodic experiences are represented by coupling the agent and its dynamic interaction with the surrounding environment.
			\\
			Elementary information units used in AMs define a temporal representation where an agent and the environment reciprocally take on the role of a \emph{context}. Temporal changes of the internal representation of the state of one of them (that Damasio calls “dispositions”) are observed as occurring in the context of the other one assuming a given state (see Fig. 2). Sequences of such patterns are stored in the AM representing
			episodes. Therefore, at least in humans and biological agents, SA is based on a \textbf{contextual} representation, which is essential
			for the emergence of the expected SA capabilities as listed in
			\citet{regazzoni-2020-multi-sensorial-generative-and-descriptive-self-awareness-models-for-autonomous-systems} Table I.
			
			\paragraph{Key element in SA knowledge}A dynamic description of agent and environment changes based on their reciprocal states is a key element for the representation of SA knowledge. This is different from many traditional AI systems, where exteroceptive sensory data sequences are often represented at a primary level \emph{without explicit contextual} information. 
		
			\textbf{Traditional AI systems do not consider contextual data}: This is different from many traditional AI systems, where exteroceptive sensory data sequences are often represented at a primary level \emph{without explicit contextual information}. As a \textbf{consequence}, high-level
			processing techniques, for example, classifiers based on supervised labeled learning \citet{regazzoni-2020-multi-sensorial-generative-and-descriptive-self-awareness-models-for-autonomous-systems}[30], \citet{regazzoni-2020-multi-sensorial-generative-and-descriptive-self-awareness-models-for-autonomous-systems}[31], \citet{regazzoni-2020-multi-sensorial-generative-and-descriptive-self-awareness-models-for-autonomous-systems}[32], use implicit contextual information to cluster such data into homogeneous groups.
			
			\textbf{A problem}: Despite the impressive classification performance that can be achieved when testing data and training experiences belong to
			the same class, the observing artificial agent cannot reliably connect such classification results to its internal dynamical state when performing similar actions to the ones performed during training, simply because its state was not observed and memorized together with the observed exteroceptive data. It is therefore not trivial to use such classifiers as building blocks for an artificial agent due to the limited adaptability. 
			
			\paragraph{} Damasio \citet{regazzoni-2020-multi-sensorial-generative-and-descriptive-self-awareness-models-for-autonomous-systems}[28] proposed dispositional units, i.e., information units representing contextualized state changes of the
			agent or the environment, for modeling “\textbf{cognitive cycles}”,
			i.e., episodes that can be found as the \emph{basis of human self-awareness}. Moreover, he suggests that dispositional units can
			be hierarchically organized at different levels in the brain, for
			example for describing \emph{temporal-causal} representations in the
			activation and processing results of neuron maps dedicated to
			different goals. Consequentially, an AMs should be hierarchical structured for providing SA models, and thus dispositional
			units’ representations should be defined such that they can be organized in multi-level hierarchies (see Fig. 3).
			\begin{figure*}
				\centering
				\includegraphics[width=0.7\textwidth]{/home/donkarlo/Dropbox/projs/research/assets/regazzoni-2020-multi-sensorial-generative-and-descriptive-self-awareness-models-for-autonomous-systems-fig-3}
				\caption{regazzoni-2020-multi-sensorial-generative-and-descriptive-self-awareness-models-for-autonomous-systems-fig-3}
				\label{fig:regazzoni-2020-multi-sensorial-generative-and-descriptive-self-awareness-models-for-autonomous-systems-fig-3.png}
			\end{figure*}
			
			\paragraph{Autobiographical self} Neuroscience observations show that the parts of the human
			brain storing AMs are linked and can exchange neural signals with other parts of the brain known to be activated within conscious inference processes [33]. The role of such neural maps is to analyze—at different hierarchical levels—proprioceptive and exteroceptive sensorial data originating from the current agent’s experiences. The process of \emph{recalling} and \emph{comparing multi-level AMs}\emph{ with respect to current experiences} is an \emph{integral capability} of self-awareness related to inference and anomaly detection, which is defined by Damasio as \textbf{autobiographical self} (AS). 
			\paragraph{Application of AS}The AS allows an agent to evaluate whether the current experience matches any episode stored in the AM.  Moreover, the AS must provide inference processes to interface with other parts of the agent’s brain (e.g., blocks dedicated to agent’s
			resource planning and control of actuators) to maintain a dynamic stability condition, i.e., homeostasis \citet{regazzoni-2020-multi-sensorial-generative-and-descriptive-self-awareness-models-for-autonomous-systems}[34]. 
			
			In a SA model, the \underline{inference capability} implies that activated AMs’ dispositional units and currently experienced data elaborated by early neural maps can be managed by the AS inference process to perform, for example, predictions on the agent’s future states. Based on the temporal-causal organization of the available episodes stored in the AM, the AS is able to predict future states at multiple abstraction levels by using generative models that represent possible alternative realizations of episodes already experienced adapted to currently observed data. As multiple episodes are stored in the AM, the AS inference processes need to identify models that better match the current experience, which requires the dispositional units’ representation in a SA model to inherently provide a discriminative property to assess current data characteristics.
			
			
			\paragraph{in AI} An artificial AS is also required to determine the difference between episodes contained in its own AMs and the current
			experiences based on an appropriate metric, which can be interpreted as the basis for the abnormality detection capability
			(see Fig. 4). 
			\begin{figure*}
				\centering
				\includegraphics[width=0.7\textwidth]{/home/donkarlo/Dropbox/projs/research/assets/regazzoni-2020-multi-sensorial-generative-and-descriptive-self-awareness-models-for-autonomous-systems-fig-4.png}
				\caption{Fig. 4: Autobiographical memory (AM) and autobiographical self (AS) as core components of a self-aware agent founded on Damasio’s model. The core-self and the proto-self process exteroceptive and proprioceptive information and store them as dispositional units in the AM. The AS is able to perform inference and anomaly detection based on the stored episodes.
				}
				\label{fig:regazzoni-2020-multi-sensorial-generative-and-descriptive-self-awareness-models-for-autonomous-systems-fig-4.png}
			\end{figure*}
			
			In order to assess the matching degree between predictions derived from the dispositional units of the set of potentially applicable episodes and the current observations, the SA agent must apply a computable metric invariant to the sensor modality. In this case, the agent should be aware that an
			abnormality, i.e., a non-stationary condition never experienced before, is currently present. Damasio does not address which specific computational neural characteristic included in the neural implementation is able to realize such computational behavior. He only suggests that such matching and prediction inference capabilities can be performed by the AS at different abstraction and temporal levels and so enabling an efficient selection of the hierarchical and dispositional representation of AMs episodes).
			\paragraph{Rise of emotions} It is worth mentioning that for natural agents, Damasio suggests that the integrated SA system composed by AM and AS can also be used as a possible explanation of higher-level human regulatory psychological phenomena such as emotions and feelings \citet{regazzoni-2020-multi-sensorial-generative-and-descriptive-self-awareness-models-for-autonomous-systems}[35]. Emotions and feelings can be considered as emergent results of evaluating current experiences based on multi-level hierarchical AMs by means of the AS \citet{regazzoni-2020-multi-sensorial-generative-and-descriptive-self-awareness-models-for-autonomous-systems}[25].
			For example, fear can emerge from the capability of detecting abnormalities, recognizing that the current experience does not match with past AMs, or it matches with AMs that describe dangerous episodes. Damasio’s model implicitly implies that AS outcomes enable an agent to incrementally update internal AM models by coding abnormal experiences into new models as well as to define a SA system that derives inferences invariant to the involved sensor modalities.
			
			
		\subsection{Haykin’s model}
		In comparison with Damasio’s work, Haykin proposes a computational framework of neuroscience observations from an engineering perspective referred to as \textbf{Cognitive Dynamic Systems (CDS)} \citet{regazzoni-2020-multi-sensorial-generative-and-descriptive-self-awareness-models-for-autonomous-systems}[36]. The proposed CDS model is based on the interactions that a \emph{Cognitive Controller} (CC) part of a CDS has to maintain at multiple levels of abstractions with a \emph{Cognitive Perceptor(CP)}.  The CP processes exteroceptive information coming from the environment at different hierarchical levels and can be seen as a hierarchical probabilistic filter, generating environment descriptions at different abstraction levels.
		\\
		Beyond providing information to higher levels, such a filter generates hierarchical feedback information to the CC, which in turn computes commands to actuators that are characterized by uncertainty. The CC block of Haykin’s model is described as a top-down structure generating outputs towards lower levels. \emph{At the bottom layer}, it directly generates outputs for the \emph{actuators}.
		\\
		The \emph{Probabilistic Reasoning Machine} (PRM), introduced in a joint paper with J. Fuster [37], organizes probabilistic information coming from the CP, i.e., percepts and errors (prediction and update processes), together with information coming from the CC, i.e., planned actions with its related
		uncertainty. Such an organization is performed over time. As can be seen in Fig. 5, Haykin’s model does \emph{not directly employ proprioceptive} sensory data but uses internal strategies to generate commands towards actuators.
		\begin{figure*}
			\centering
			\includegraphics[width=0.7\textwidth]{/home/donkarlo/Dropbox/projs/research/assets/regazzoni-2020-multi-sensorial-generative-and-descriptive-self-awareness-models-for-autonomous-systems-fig-5.png}
			\caption{Fig. 5: Hierarchically structured probabilistic reasoning machine (PRM) adopted from [37]. The cognitive perceptor (CP) processes exteroceptive information (“percepts”) at different hierarchical levels, and the cognitive controller (CC) generates outputs towards the actuators in a top-down structure. The PRM organizes probabilistic information from perception and control by data structures capturing causal-temporal interactions that are similar to “dispositional units”.
			}
			\label{fig:regazzoni-2020-multi-sensorial-generative-and-descriptive-self-awareness-models-for-autonomous-systems-fig-5.png}
		\end{figure*}
		The \textbf{main goal} of the PRM is to maintain a meta-level representation of the \emph{perception-action} cycle based on switching and adapting the behavior of CP and CC.
		
		\paragraph{The relation between Haykin and Damasio}As the control strategies embedded in the CP are hypothesized to maintain homeostasis, i.e., a dynamic equilibrium between the agent’s state and the changes in the environment, the PRM is contributing to the continuous regulation of agents’ processes by providing switching suggestions to CP and CC. Those suggestions are implicitly based on the knowledge that an agent must have been learned from experiences, and it is represented within the PRM. \textbf{In this sense, the PRM block is strictly related to Damasio’s SA model}, as it has to process representations of actions and percepts organized in a \textbf{temporal-causal} order, and
		the \emph{PRM block can be related to AM and AS as SA} model capabilities.
		\paragraph{} The PRM elementary representation requires organizing perception and actions into data structures capturing causal and temporal interactions between the agent’s actions and precepts originated from the environment. Dispositional information units, as described by Damasio, also represent such interactions but are different because the state of the agent is directly observed by itself. This can be considered either as feedback for the SA agent to evaluate the outcome of commands it has sent to actuators and lower-level blocks or as a multi-sensor source of proprioceptive signals representing the agent state to itself. This concept is exploited in  \cite{regazzoni-2020-multi-sensorial-generative-and-descriptive-self-awareness-models-for-autonomous-systems} SA model (depicted in Fig. 10). If this second view is taken, a modified PRM can be considered as a structure where appropriately modified dispositional units are processed based
		on hierarchical filters that work on proprioceptive feedback and in a bottom-up way also in the CC. 
		\paragraph{} In Haykin’s approach, the \emph{focus is on control} instead of SA. Therefore, the PRM is designed to make a CDS capable of using interactive behavioral rules to switch among different perceptions and action modalities adaptively. Such inferences can drive actions that the agent’s sensors and actuators should accomplish anticipatorily by activating available models in the PRM memory when it performs a given experience. This allows the CDS of an attention capability towards preferred control or sensing actions in a given homeostatic cycle. In the case of the SA model discussed here, the agent has no direct knowledge of the control strategy actions that are generated by its own decision-making subsystem, but it can observe and fuse their outcomes through parallel proprioceptive feedback from sensors coupled with exteroceptive environmental observations. Haykin’s model, however, suggests how a SA model can provide useful data to adapt decision making processes behaviors at homogeneous hierarchical levels to the PRM. For example, SA can share with decision-making estimates of present and predicted contextualized states as well as errors and deviations of models describing previous agent
		experiences.
		\paragraph{}Furthermore, Haykin’s model facilitates identifying temporal variations of uncertainty associated with actions and percepts, which is a key aspect for addressing a proper computational framework for the CDS design, i.e., a PRM 
		in \cite{regazzoni-2020-multi-sensorial-generative-and-descriptive-self-awareness-models-for-autonomous-systems} SA model. Moreover, the organization of a PRM at multiple abstraction levels is coherent with the hierarchical characteristics of Damasio’s dispositional units. In this case, actions and percepts as temporal aggregations (equivalent to dispositional units) at different hierarchical levels can describe the joint state of lower-level parts of the agent body down to the directly observed proprioceptive and exteroreceptive characteristics of the agent and the environment. Although Haykin’s approach does not provide a specific probabilistic model for uncertainties and dependencies, it proposes a Bayesian framework to model uncertainty and causality and
		make inferences computationally, e.g., parametric conditional probability models.
		
		\paragraph{}Although the goal of Haykin is not to specify a univocal PRM model but to provide a generic framework for CDSs, his model is essential for addressing the main techniques for SA in artificial agents. His work then suggests that SA models originating from a computational domain should be associated with an appropriate calculus of uncertainty propagation. In \citet{regazzoni-2020-multi-sensorial-generative-and-descriptive-self-awareness-models-for-autonomous-systems}[38], a CDS inspired by such a probabilistic approach uses a simple PRM unit that allows a vision system on a mobile platform to make inferences about future states. Moreover, Haykin’s work does not directly provide a unitary view of the techniques that could be used to store a coherent multi-level generative and discriminative PRM’s knowledge. Nonetheless, \cite{regazzoni-2020-multi-sensorial-generative-and-descriptive-self-awareness-models-for-autonomous-systems} work
		integrates Haykin’s viewpoint on uncertainty and makes a relation between the perception-control blocks and Damasio’s
		theory, which includes AM and AS and dispositional units.
		\cite{regazzoni-2020-multi-sensorial-generative-and-descriptive-self-awareness-models-for-autonomous-systems}Fig. 10 displays a revisited block scheme of Haykin’s model.
		
		\subsection{Friston’s model}
		Another relevant cognitive framework for SA that aims at
		establishing links between neuroscientific observations and
		computational models is the one proposed by Friston \citet{regazzoni-2020-multi-sensorial-generative-and-descriptive-self-awareness-models-for-autonomous-systems}[39],
		\citet{regazzoni-2020-multi-sensorial-generative-and-descriptive-self-awareness-models-for-autonomous-systems}[27]. Here, Bayesian dynamical systems are the computational
		tool that facilitates an uncertain and hierarchical self-coherent representation to describe and generate simulations
		of inferences performed by the human brain utilizing neuron firings. Friston’s approach is innovative in the context of
		developing self-aware models for artificial agents due to the following characteristics: i) It formally relates a statistical me-
		chanics’ optimization framework, that can be summarized as free energy and variational based reasoning, with Bayesian
		inference. It founds a theoretical domain for describing SA knowledge and models (in the AM) as well as inference (in
		the AS). ii) It proposes the concept of generalized states (GS) to develop a class of computational and hierarchical Bayesian
		filters that we use to embed representation and inference over dispositional temporal knowledge.
		\paragraph{} The good regulator theorem [35] states that “every good regulator of a system must be a model of that system”. In this
		sense, SA models can be considered as joint discriminative and generative models that contribute to the regulation of an artificial agent representing an adaptive code of the system itself and its incremental experiences at the same time. The
		free energy principle represents an optimization criterion that can be related with a variational computational framework to
		both define and discover optimal SA models from a given set of dynamic experiences, i.e., available data sequences
		originating from exteroceptive and proprioceptive sensors.
		\paragraph{} In [27], Friston suggests that establishing an equivalence between a probabilistic and a mechanical statistics’ representation of the dynamic equilibrium in the sensed internal state and the contextual environment allows one to explain
		the observed neuron firing in the human brain through the free energy concept. He further shows that Bayesian inference is an
		equivalent way to do so. As SA in humans is based on brain inference processes, probabilistic dynamic representation and
		inference models are good candidates to form the \textbf{language} for expressing a SA model in an artificial agent as well. Such
		models must be capable of including temporally ordered descriptions of contextual dependencies between proprioceptive
		and exteroceptive variables.
		\paragraph{} The variational computational representation and inference
		techniques he proposes clarify how different models can
		describe statistically different sensorial experiences that can
		be seen as trajectories in generalized spaces. The models
		can also provide explicit measurements to evaluate or to
		discriminate best-fitting models of new observed sequences.
		At the same time, the same models, that can include multiple conditionally connected random variables at different
		hierarchical and temporal levels, are capable of predicting
		multi-level, temporal data series characterized by the same
		statistical properties of the training experiences from which
		they can be learned (thanks to their generative nature). Such
		a model, if used within the SA model of an artificial agent,
		together with appropriate learning techniques, can facilitate
		incremental model creation. An AS can so actively memorize
		incrementally generative and discriminative new models in the
		AM by processing sensorial experiences. Such models have to
		capture different causality interactions between the agent and
		the environment and serve as the basis for \emph{symbolic} descriptors
		in an artificial SA agent.
		\paragraph{} The SA capability of abnormality detection can also be
		explained with Friston’s model, i.e., the free energy that
		models generate when the AS compares them to a new
		experience. A metric can be defined to evaluate the amount
		of abnormality which is related to a particular component
		of free energy, describing the orthogonal perturbations to the
		dynamic equilibrium condition described by the model. Such
		a metric enables the AS to rank the abnormalities measured
		from a set of AM models, so relating the discriminative
		SA property of the model to the abnormality detection and
		inference capabilities.
		\paragraph{}Contribution ii) to the SA model definition is a specific class
		of Bayesian filters, namely GS filters. Friston et al. [40] explain
		that thanks to such filters, active and variational Bayesian
		inference techniques can be obtained with better performances.
		GSs describe a class of trajectories in terms of generalized
		coordinates of motion. The resulting model can be shown to
		better describe the dynamical nature of the pattern in terms
		of temporal and causal explainability of dependencies among
		states as well as computational benefits. In a SA model,
		hierarchical Bayesian models derived from GS filters can
		provide the description language for the AM, depicted as
		individual “pages” in Fig. 6. \citet{regazzoni-2020-multi-sensorial-generative-and-descriptive-self-awareness-models-for-autonomous-systems} shows how these models
		can be learned by observing proprioceptive and exteroceptive
		data series both independently and in a coupled way that is
		oriented to represent their dispositional nature. Such filters can
		be used both as generative and discriminative models, and they
		can be good candidates to be related to the “good regulator”
		code [35], as they can represent the rules that describe the
		agent, as well as such rules, can be used by the agent to predict
		the dynamic contextualized behavior where it is acting.
		\begin{figure*}
			\centering
			\includegraphics[width=0.7\textwidth]{/home/donkarlo/Dropbox/projs/research/assets/regazzoni-2020-multi-sensorial-generative-and-descriptive-self-awareness-models-for-autonomous-systems-fig-6.png}
			\caption{\citet{regazzoni-2020-multi-sensorial-generative-and-descriptive-self-awareness-models-for-autonomous-systems} Fig. 6}
			\label{fig:regazzoni-2020-multi-sensorial-generative-and-descriptive-self-awareness-models-for-autonomous-systems-fig-6.png}
		\end{figure*}
		\paragraph{} Coupled proprioceptive and exteroceptive signals of GS
		filters can efficiently represent Damasio’s dispositional units
		in a SA model. For example, a Switching Dynamic Bayesian
		Network (DBN) [41], [42] uses multi-level discrete and con-
		tinuous generalized states as variables that will be further
		discussed in the following sections.
		\paragraph{} Dynamic Expectation Maximization (DEM) filters [40] are
		hierarchical parametric GS filters that are here used to
		derive coupled GS-DBNs. These filters have been shown to
		jointly perform parameter, hyperparameters, and GS estimations within a continuous variable Bayesian network that is
		by itself a fully continuous DBN. However, discrete variables
		are needed in a SA model too. Such variables are used to
		represent different models (i.e., different pages in the AM
		structure) and to provide finer level discriminative descriptions
		of learned models to determine a different class of probabilistic
		dependencies within an episode, useful both for generative
		and discriminative purposes. Coupled GS-DBNs are, therefore,
		better-suited filters than DEM, in particular when all model
		properties are necessary to reach the SA capabilities (see
		Fig. 7).
		\begin{figure*}
			\centering
			\includegraphics[width=0.7\textwidth]{/home/donkarlo/Dropbox/projs/research/assets/regazzoni-2020-multi-sensorial-generative-and-descriptive-self-awareness-models-for-autonomous-systems-fig-7.png}
			\caption{\cite{regazzoni-2020-multi-sensorial-generative-and-descriptive-self-awareness-models-for-autonomous-systems}Fig. 7}
			\label{fig:regazzoni-2020-multi-sensorial-generative-and-descriptive-self-awareness-models-for-autonomous-systems-fig-7.png}
		\end{figure*}
	
	\section{ SIGNAL REPRESENTATION AND MODEL LEARNING}
		\subsection{Bio-inspired SA Model}
		The main difference between Haykin’s and Damasio’s models is that the objective of the latter lies in the bottom-up
		explanation of neuroscientific observations, while the first one
		focuses on the definition of control within a CDS. Similar
		to Haykin’s model, Friston’s approach is based on a Bayesian
		and computationally efficient approach for SA representations.
		Friston’s approach is more focused on a bottom-up joint analysis of proprioceptive and exteroceptive signals, while Haykin’s
		model aims at providing a framework for defining computational aspects of perception-action cycle decision making
		outcomes towards actuators in a CDS. A computational SA
		model for an artificial agent can be obtained by merging
		different aspects of the three frameworks. Such SA model
		should include SA properties as discussed in Section I and
		enlisted in \cite{regazzoni-2020-multi-sensorial-generative-and-descriptive-self-awareness-models-for-autonomous-systems}Table II.
		\begin{figure*}
			\centering
			\includegraphics[width=0.7\textwidth]{/home/donkarlo/Dropbox/projs/research/assets/regazzoni-2020-multi-sensorial-generative-and-descriptive-self-awareness-models-for-autonomous-systems-table-ii.png}
			\caption{\cite{regazzoni-2020-multi-sensorial-generative-and-descriptive-self-awareness-models-for-autonomous-systems} Table II}
			\label{fig:regazzoni-2020-multi-sensorial-generative-and-descriptive-self-awareness-models-for-autonomous-systems-table-ii.png}
		\end{figure*}
		\paragraph{How to build new models from big errors}
		\citet{regazzoni-2020-multi-sensorial-generative-and-descriptive-self-awareness-models-for-autonomous-systems} Fig. 6 and Fig. \citet{regazzoni-2020-multi-sensorial-generative-and-descriptive-self-awareness-models-for-autonomous-systems} 8 depict how the AM can be represented as
		a book containing \textbf{multiple pages}. Each page corresponds to
		a probabilistic model learned based on observed sequences of
		dispositional units during different experiences. Such a model
		should be both generative and discriminative. 
		\begin{figure*}
			\centering
			\includegraphics[width=0.7\textwidth]{/home/donkarlo/Dropbox/projs/research/assets/regazzoni-2020-multi-sensorial-generative-and-descriptive-self-awareness-models-for-autonomous-systems-fig-8.png}
			\caption{\cite{regazzoni-2020-multi-sensorial-generative-and-descriptive-self-awareness-models-for-autonomous-systems} Fig 8 Models in the agent’s memory produce error mea-
				surements as observations arrive. The fittest model is iden-
				tified/discriminated and abnormalities (high errors w.r.t a
				threshold) are extracted from it. Such high errors are then
				used to create new models incrementally as shown in Fig. 6.
			}
			\label{fig:regazzoni-2020-multi-sensorial-generative-and-descriptive-self-awareness-models-for-autonomous-systems-fig-8.png}
		\end{figure*}	
		\paragraph{Basis for initialization} \citet{regazzoni-2020-multi-sensorial-generative-and-descriptive-self-awareness-models-for-autonomous-systems}Fig. 6 shows that
		an initial reference model serves as a \textbf{basis for initialization}.
		This initial model should represent quite general behavioral rules obtained in correspondence to a reference experience. For example, as \citet{regazzoni-2020-multi-sensorial-generative-and-descriptive-self-awareness-models-for-autonomous-systems} will show, it can contain knowledge useful to
		predict the agent’s state, even if the environment does not interact with it, and therefore exteroceptive signals do not provide significant contextual temporal and causal information. In that case, the expected agent’s state changes are null, except for random perturbations, and state and its derivatives estimated from proprioceptive signals can be stationary.
		\paragraph{}The initial model and all generated models in the AM must be generative, i.e., they should be capable, under the effect of a latent null variable, to generate a sequence of predictions in the form of expected probabilistic properties of the dispositional unit that could be observed as evidence. This has to happen as part of the inference process in the AS
		module. The AS module must be capable of comparing the current set of dispositional units from the current experience with the predictions of the \textbf{currently \emph{activated} AM page}. This comparison has to produce both an evaluation of the \textbf{mismatch degree} between predicted and observed dispositional units but also to describe such errors and memorizing them for further steps. When mismatches are relevant, i.e., abnormalities with respect to the initial model are too high, the sequences of dispositional units and related errors (generalized errors) are processed for describing the \textbf{new experience}. The model creation phase organizes such data series that can be considered
		as sparse acquisitions of generalized errors with respect to
		selected AM available models, e.g., by using unsupervised
		machine learning tools into new models. The results of the
		analysis of the sparse generalized errors are described again
		in terms of behavioral rules expressed using generative models
		with the same language of the initial models. \textbf{Such new models
		can be seen as new pages to be added to the AM book.}
		\textbf{Memorization} includes the capability to organize the learned
		models within the AM model as incremental pages in a book.
		\citet{regazzoni-2020-multi-sensorial-generative-and-descriptive-self-awareness-models-for-autonomous-systems} Section II-B describes how this can be obtained starting from
		free energy and generalizes state concepts in a way inspired
		to Friston’s approach.
		\paragraph{} \citet{regazzoni-2020-multi-sensorial-generative-and-descriptive-self-awareness-models-for-autonomous-systems}Fig. 8 highlights the inference capability of the AS when
		the AM is composed of multiple pages, i.e., to \textbf{discriminatively
		select a page that better fits to the current experience}. Again,
		this can be obtained by comparing the generalized errors obtained by processing in multiple parallel models and evaluating
		when the minimum detected error is sufficiently small. The
		page which produced such a set of generalized error also
		contains the causal and temporal knowledge to predict the
		dynamic evolution of the contextual state of the agent and
		the environment, so providing to the agent a symbolic and
		continuous SA description of what is happening compared
		to past experiences. The minimum abnormality criterion to
		discriminate the most fitting model can be considered as the
		selection of the model characterized by the lowest generalized
		error, evaluated by using an appropriate metric. Therefore, the
		SA discriminative capability results by comparing the current
		experience to the generated predictions of a set of models of
		experiences available at a given moment in an agent. \citet{regazzoni-2020-multi-sensorial-generative-and-descriptive-self-awareness-models-for-autonomous-systems}Fig. 8
		shows how the inference process in the AS can also generate
		useful information for decision making. In particular, the set of predictions and related errors derived from comparing
		activated models with the current dispositional units can be
		used by a decision making block to plan resources usage as
		well as to decide among alternative actuator signals to perform
		planned actions.
		
		\paragraph{} \citet{regazzoni-2020-multi-sensorial-generative-and-descriptive-self-awareness-models-for-autonomous-systems}Fig. 9 shows that, in contrast to Haykin’s theory, the SA
		model does not explain the perception-action cycle, so it
		does not include a hierarchical control block. Instead, pro-
		prioceptive signals provided by observing agent actuators are
		processed in parallel in a bottom-up way with exteroceptive
		signals processed in the block defined as Perception in \citet{regazzoni-2020-multi-sensorial-generative-and-descriptive-self-awareness-models-for-autonomous-systems}[43]. As
		can be seen in \citet{regazzoni-2020-multi-sensorial-generative-and-descriptive-self-awareness-models-for-autonomous-systems}Fig. 10, the PRM is replaced by the SA model
		as it aims to organize extero and proprio percepts, with the
		latter being considered as the feedback generated by actuators
		controls by the agent itself.
		\begin{figure*}
			\centering
			\includegraphics[width=0.7\textwidth]{/home/donkarlo/Dropbox/projs/research/assets/regazzoni-2020-multi-sensorial-generative-and-descriptive-self-awareness-models-for-autonomous-systems-fig-9.png}
			\caption{\cite{regazzoni-2020-multi-sensorial-generative-and-descriptive-self-awareness-models-for-autonomous-systems} Fig 9 Relationships between exteroceptive states (bottom) and generalized states (top). Two consecutive states are ab-
				stracted into a generalized state that has information about i)
				the current state (depicted by the shape of the puzzle piece)
				and ii) its derivative (depicted by the arrows pointing at the
				expected state’s change in the succeeding time instant). Note
				that the same logic can be applied to proprioceptive data (green
				puzzle pieces).
			}
			\label{fig:regazzoni-2020-multi-sensorial-generative-and-descriptive-self-awareness-models-for-autonomous-systems-fig-9.png}
		\end{figure*}
		\paragraph{}For the proposed model to be effective, it must fulfill the
		properties listed in Table II. In particular, \citet{regazzoni-2020-multi-sensorial-generative-and-descriptive-self-awareness-models-for-autonomous-systems} note that the
		content of AM pages represents models organized into random variables that should come from observations of dispositional
		units (i.e., interactive variables embedding causal and temporal aspects). They are random variables at multiple hierarchical
		levels. Moreover, the SA process has to be autopoietic in the sense that it should be able to learn new pages of the
		AM book from computed generalized errors by generating predictions from pages already available in the AM book. As a
		function of generalized errors over the generalized state-space describes the differences between the current experience and
		the existing AM page, this means that a new page generated during model creation should provide a generalized null error,
		i.e., that learning process should be capable of representing a function of generalized error over the generalized state space
		as a book page model.
		
		\section{}
	
	\section{SA in computational context} In a computational context, self-awareness (SA) is a capability of an autonomous system to describe the acquired experience about itself and its surrounding environment with appropriate models and correlate them incrementally with the currently perceived situation to expand its knowledge continuously.
	
	\section{Definition from  sensor data and signal processing perspective}: An artificial agent is considered self-aware if it can \textbf{dynamically observe itself} and \textbf{its surrounding environment} through different \textbf{proprioceptive} and \textbf{exteroceptive} sensors and \textbf{learn} and \textbf{maintain a contextual representation} by processing the observed multi-sensorial data. 
		
	
	
	
	
	
	\bibliography{/home/donkarlo/Dropbox/projs/research/refs.bib}
\end{document}